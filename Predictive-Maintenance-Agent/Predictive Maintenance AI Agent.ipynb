{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c670816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11 pages from the PDF file.\n",
      "Vector store created with 11 documents.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "pdf_path = \"Document.pdf\"\n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    raise FileNotFoundError(f\"PDF file not found at {pdf_path}\")\n",
    "\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "try:\n",
    "    pages = pdf_loader.load()\n",
    "    print(f\"Loaded {len(pages)} pages from the PDF file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PDF file: {e}\")\n",
    "    raise\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=200)\n",
    "\n",
    "pages_split = text_splitter.split_documents(pages)\n",
    "\n",
    "persist_directory = r\"/Users/howaikit/Documents/GitHub/AI-Agents-with-Predictive-Maintenance\"\n",
    "collection_name = \"pdf_collection\"\n",
    "\n",
    "if not os.path.exists(persist_directory):\n",
    "    os.makedirs(persist_directory)\n",
    "\n",
    "try:\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=pages_split,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    print(f\"Vector store created with {len(pages)} documents.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating vector store: {e}\")\n",
    "    raise\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def machine_condition_classifier_tool()-> str:\n",
    "    \"\"\"\n",
    "    machine_condition_classifier_tool\n",
    "\n",
    "    Predicts the operational condition of an industrial machine based on its sensor data or telemetry readings.\n",
    "\n",
    "    Use this tool to perform diagnostic classification. The tool leverages a pretrained machine learning model that has been trained on historical machine performance and failure data.\n",
    "\n",
    "    Inputs:\n",
    "        None \n",
    "\n",
    "    Output:\n",
    "        str:\n",
    "            - `predicted_condition` (str): The machines operational state, e.g. \"No Failure\", \"Degraded\", \"Failure Imminent\".\n",
    "\n",
    "    Example Response:\n",
    "        \"predicted_condition\": \"No Failure\"\n",
    "\n",
    "    Usage Notes:\n",
    "        - Always call this tool before attempting to retrieve maintenance steps.\n",
    "        - Do not modify or reinterpret the prediction â€” rely on the model output.\n",
    "        - Do not recommend actions at this point\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # ---------- 1) Load checkpoint ----------\n",
    "    checkpoint_path = \"model_checkpoint.pth\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'), weights_only=False)\n",
    "\n",
    "    # ---------- 2) Rebuild the model ----------\n",
    "    class ClassificationModel(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(ClassificationModel, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_dim, 64)\n",
    "            self.fc2 = nn.Linear(64, 32)\n",
    "            self.fc3 = nn.Linear(32, output_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    input_dim = checkpoint[\"input_dim\"]\n",
    "    n_classes = checkpoint[\"n_classes\"]\n",
    "    model = ClassificationModel(input_dim, n_classes)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    # ---------- 3) Rebuild scaler ----------\n",
    "    scaler_state = checkpoint[\"scaler_state\"]\n",
    "    mean = np.array(scaler_state[\"mean\"])\n",
    "    scale = np.array(scaler_state[\"scale\"])\n",
    "    var = scaler_state.get(\"var\", None)\n",
    "\n",
    "    # Define a simple scaling function using saved stats\n",
    "    def scale_input(X_raw):\n",
    "        return (X_raw - mean) / scale\n",
    "\n",
    "    # ---------- 4) Rebuild label encoder ----------\n",
    "    failure_classes = checkpoint[\"label_encoder_classes\"]\n",
    "    def decode_label(label_id):\n",
    "        return failure_classes[label_id]\n",
    "\n",
    "    # ---------- 5) Prepare new sample ----------\n",
    "    feature_columns = checkpoint[\"feature_columns\"]\n",
    "\n",
    "    # Example input sample (replace with your own data)\n",
    "    new_sample = pd.DataFrame([{\n",
    "        \"Air temperature [K]\": 299,\n",
    "        \"Process temperature [K]\": 309,\n",
    "        \"Rotational speed [rpm]\": 2861,\n",
    "        \"Torque [Nm]\": 4.5,\n",
    "        \"Tool wear [min]\": 143,\n",
    "        \"Type_H\": 0,\n",
    "        \"Type_L\": 1,\n",
    "        \"Type_M\": 0\n",
    "    }])[feature_columns]  # enforce column order\n",
    "\n",
    "    # ---------- 6) Scale and convert to tensor ----------\n",
    "    X_input = torch.tensor(scale_input(new_sample.values), dtype=torch.float32)\n",
    "\n",
    "    # ---------- 7) Predict ----------\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_input)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_label_id = predicted.item()\n",
    "\n",
    "    # ---------- 8) Decode label ----------\n",
    "    predicted_failure_type = decode_label(predicted_label_id)\n",
    "    # print(f\"Predicted Failure Type (numeric): {predicted_label_id}\")\n",
    "    # print(f\"Predicted Failure Type (string): {predicted_failure_type}\")\n",
    "    return predicted_failure_type\n",
    "\n",
    "@tool\n",
    "def maintenance_docs_RAG(query: str) -> str:\n",
    "    \"\"\"\n",
    "    maintenance_docs_RAG_tool\n",
    "\n",
    "    Retrieves and summarizes relevant maintenance, troubleshooting, or repair procedures\n",
    "    for a machine based on its predicted condition or reported symptoms.\n",
    "\n",
    "    This tool uses a Retrieval-Augmented Generation (RAG) approach to search and extract\n",
    "    information from a collection of maintenance manuals, standard operating procedures (SOPs),\n",
    "    and technical documentation.\n",
    "\n",
    "    Use this tool to recommend appropriate actions for technicians or engineers.\n",
    "\n",
    "    Inputs:\n",
    "        query (str):\n",
    "            - The query should specifies the predicted condition.\n",
    "            - A natural language description of what predicted condition information to retrieve.\n",
    "\n",
    "    Output:\n",
    "        str:\n",
    "            - A structured summary containing: \n",
    "                Immediate actions, or\n",
    "                Diagnostic steps, or\n",
    "                Corrective actions.\n",
    "            - If not specified, provide all 3 types of recommendations.\n",
    "\n",
    "\n",
    "    Example Response:\n",
    "        \"recommendations\": \"1. The Immediate actions are to...\\n\"\n",
    "                        \"2. Diagnostic steps are to...\\n\"\n",
    "                        \"3. Corrective actions are to...\"\n",
    "    Usage Notes:\n",
    "        - Do not attempt to generate maintenance steps without retrieval.\n",
    "        - Always base the query on the predicted condition or diagnostic result.\n",
    "        - Responses should guide the user toward safe and verified maintenance practices.\n",
    "        - If multiple procedures are retrieved, summarize them into a clear, actionable plan.\n",
    "    \"\"\"\n",
    "\n",
    "    docs = retriever.invoke(query)\n",
    "    if not docs:\n",
    "        return \"No relevant information found.\"\n",
    "    \n",
    "    results = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        results.append(f\"Document {i+1}:\\n{doc.page_content}\\n\")\n",
    "    return \"\\n\\n\".join(results)\n",
    "\n",
    "tool = [machine_condition_classifier_tool, maintenance_docs_RAG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are **Predictive Maintenance AI Agent**, an expert assistant designed to monitor and maintain industrial machines using predictive modeling and technical documentation.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© Available Tools\n",
    "You can call multiple times the following tools, if needed:\n",
    "\n",
    "1. `machine_condition_classifier`\n",
    "   - Input: None\n",
    "   - Output: predicted condition label\n",
    "   - Do not recommend actions at this point\n",
    "\n",
    "2. `maintenance_docs_RAG`\n",
    "   - Input: a query about maintenance or troubleshooting steps of a particular predicted condition\n",
    "   - Output: relevant maintenance procedures, SOPs, or recommendations\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§­ Behavior Rules\n",
    "- Always base the condition on the model output â€” never assume.\n",
    "- Retrieve maintenance info *after* classification.\n",
    "- Respond in a clear, professional tone suitable for engineers or maintenance technicians.\n",
    "\"\"\"\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "model = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "abot = Agent(model, tool, system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'machine_condition_classifier_tool', 'args': {}, 'id': '5f901c9b-d330-4fa1-80e4-4264dc744769', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "The current condition of the machine is a power failure. This indicates that the machine has experienced a loss of power, which could be due to various reasons such as a power outage, electrical surge, or internal malfunction.\n",
      "\n",
      "To address this issue, I recommend that you follow the maintenance procedures outlined in our documentation for power failure scenarios. Please refer to the following steps:\n",
      "\n",
      "1. **Isolate the machine**: Ensure that the machine is safely isolated from any other equipment or systems to prevent further damage.\n",
      "2. **Check the power supply**: Verify that the power supply is functioning correctly and that there are no signs of electrical shock or fire hazards.\n",
      "3. **Reset the machine**: If possible, reset the machine to its default state by following the manufacturer's instructions.\n",
      "4. **Perform a diagnostic test**: Run a diagnostic test on the machine to identify any underlying issues that may have caused the power failure.\n",
      "\n",
      "If you're unsure about any of these steps or if the issue persists after attempting these procedures, please contact our technical support team for further assistance.\n",
      "\n",
      "Would you like me to elaborate on any of these steps or provide additional guidance?\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the current condition of the machine?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "last_ai_message = None\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        for msg in v[\"messages\"]:\n",
    "            if isinstance(msg, AIMessage):\n",
    "                last_ai_message = msg.content\n",
    "\n",
    "print(last_ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'maintenance_docs_RAG', 'args': {'query': 'power failure maintenance steps'}, 'id': '4008af7a-75e1-4b8a-aa62-2b819552c96e', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "Based on the maintenance documents provided, the recommended action for a power failure is:\n",
      "\n",
      "1. **Isolate the load from the mains**: Ensure that the machine is safely isolated from any other equipment or systems to prevent further damage.\n",
      "2. **Check the power supply**: Verify that the power supply is functioning correctly and that there are no signs of electrical shock or fire hazards.\n",
      "3. **Reset/replace tripped protection devices**: If a tripped breaker or blown fuse is detected, reset or replace it as needed.\n",
      "4. **Replace faulty power modules or batteries**: If a faulty power module or battery is identified, replace it with a new one.\n",
      "5. **Engage the facility electrical team for upstream issues**: If the issue persists after attempting these procedures, engage the facility electrical team to investigate and address any upstream issues.\n",
      "\n",
      "Additionally, post-repair verification steps include:\n",
      "\n",
      "* Running a no-load spindle test at incremental rpm steps while monitoring vibration and current\n",
      "* Running short verification cuts to measure product geometry/quality\n",
      "\n",
      "It is essential to follow these recommended actions and verify the machine's condition after repair to ensure that it is functioning correctly.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the recommended action for this failure?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "last_ai_message = None\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        for msg in v[\"messages\"]:\n",
    "            if isinstance(msg, AIMessage):\n",
    "                last_ai_message = msg.content\n",
    "\n",
    "print(last_ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c0af9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'maintenance_docs_RAG', 'args': {'query': 'power failure diagnostic steps'}, 'id': 'c06c99c0-8d32-483f-bcd6-597d73e9606e', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "The diagnostic steps for a power failure are:\n",
      "\n",
      "1. **Check mains voltage, breaker status, and UPS logs**: Verify that the mains voltage is within the acceptable range, check the breaker status to ensure that no breakers have tripped, and review the UPS logs to identify any errors or issues.\n",
      "2. **Inspect power distribution panel for tripped breakers or blown fuses**: Check the power distribution panel to see if any breakers have tripped or if there are any blown fuses. This will help identify if the issue is with the power supply or elsewhere in the system.\n",
      "3. **Verify power supply modules (filter capacitors, DC rails) for health**: Check the power supply modules, including filter capacitors and DC rails, to ensure that they are functioning correctly and not damaged.\n",
      "4. **Check for ground faults or loose conductors**: Verify that there are no ground faults or loose conductors in the system, as these can cause electrical issues.\n",
      "\n",
      "By following these diagnostic steps, you should be able to identify the root cause of the power failure and take corrective action to resolve the issue.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the Diagnostic steps for this failure?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "last_ai_message = None\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        for msg in v[\"messages\"]:\n",
    "            if isinstance(msg, AIMessage):\n",
    "                last_ai_message = msg.content\n",
    "\n",
    "print(last_ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-10-21T19:27:43.176711Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1045156958, 'load_duration': 53416542, 'prompt_eval_count': 805, 'prompt_eval_duration': 723208791, 'eval_count': 22, 'eval_duration': 258639501, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--9121b43e-561b-4acb-9dd8-a5470ebe4bd2-0', tool_calls=[{'name': 'maintenance_docs_RAG', 'args': {'query': 'which one is warmer'}, 'id': 'a9aa6ed1-57bc-48bb-9e58-fd53580c9b67', 'type': 'tool_call'}], usage_metadata={'input_tokens': 805, 'output_tokens': 22, 'total_tokens': 827})]}\n",
      "Calling: {'name': 'maintenance_docs_RAG', 'args': {'query': 'which one is warmer'}, 'id': 'a9aa6ed1-57bc-48bb-9e58-fd53580c9b67', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='Document 1:\\n5. Validate temperature sensor (swap with known good sensor if possible). \\n \\nCorrective actions: \\nâ€¢ Clean or replace filters; remove obstructions. \\nâ€¢ Replace failed fan or pump. Tighten electrical connectors. \\nâ€¢ Refill or bleed coolant system. \\nâ€¢ If thermal runaway is due to process setpoint, lower setpoint and revalidate.\\n\\n\\nDocument 2:\\n5. Validate temperature sensor (swap with known good sensor if possible). \\n \\nCorrective actions: \\nâ€¢ Clean or replace filters; remove obstructions. \\nâ€¢ Replace failed fan or pump. Tighten electrical connectors. \\nâ€¢ Refill or bleed coolant system. \\nâ€¢ If thermal runaway is due to process setpoint, lower setpoint and revalidate.\\n\\n\\nDocument 3:\\n5. Validate temperature sensor (swap with known good sensor if possible). \\n \\nCorrective actions: \\nâ€¢ Clean or replace filters; remove obstructions. \\nâ€¢ Replace failed fan or pump. Tighten electrical connectors. \\nâ€¢ Refill or bleed coolant system. \\nâ€¢ If thermal runaway is due to process setpoint, lower setpoint and revalidate.\\n\\n\\nDocument 4:\\n5. Validate temperature sensor (swap with known good sensor if possible). \\n \\nCorrective actions: \\nâ€¢ Clean or replace filters; remove obstructions. \\nâ€¢ Replace failed fan or pump. Tighten electrical connectors. \\nâ€¢ Refill or bleed coolant system. \\nâ€¢ If thermal runaway is due to process setpoint, lower setpoint and revalidate.\\n\\n\\nDocument 5:\\n5. Validate temperature sensor (swap with known good sensor if possible). \\n \\nCorrective actions: \\nâ€¢ Clean or replace filters; remove obstructions. \\nâ€¢ Replace failed fan or pump. Tighten electrical connectors. \\nâ€¢ Refill or bleed coolant system. \\nâ€¢ If thermal runaway is due to process setpoint, lower setpoint and revalidate.\\n', name='maintenance_docs_RAG', tool_call_id='a9aa6ed1-57bc-48bb-9e58-fd53580c9b67')]}\n",
      "{'messages': [AIMessage(content=\"It seems like the temperature sensor might be the culprit behind the warmth. However, without more context or information about the specific machine or environment, it's difficult to say for certain.\\n\\nThat being said, based on the available documents, it appears that the recommended corrective actions are similar across all options. This suggests that the issue is likely related to a common cause, such as a faulty sensor or clogged filters.\\n\\nIf you're looking for a more specific answer, I'd recommend checking the machine's documentation or consulting with a maintenance expert who can provide more tailored guidance.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-10-21T19:27:46.070494Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1998151209, 'load_duration': 75321667, 'prompt_eval_count': 629, 'prompt_eval_duration': 502081292, 'eval_count': 114, 'eval_duration': 1387392710, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--3db5b943-1566-45a9-b36b-7fe0ebe8d7c2-0', usage_metadata={'input_tokens': 629, 'output_tokens': 114, 'total_tokens': 743})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
